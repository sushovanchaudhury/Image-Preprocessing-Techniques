{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the images from the provided path\n",
        "agriculture = cv2.imread('/content/drive/MyDrive/agriculture.jpg')\n",
        "manufacturing = cv2.imread('/content/drive/MyDrive/manufacturing.jpg')\n",
        "road = cv2.imread('/content/drive/MyDrive/road.jpg')\n",
        "medical = cv2.imread('/content/drive/MyDrive/medical.jpg')\n",
        "satellite = cv2.imread('/content/drive/MyDrive/satellite.jpg')\n",
        "\n",
        "# Advanced Noise Reduction: Bilateral Filter\n",
        "def bilateral_filter(image):\n",
        "    return cv2.bilateralFilter(image, 9, 75, 75)\n",
        "\n",
        "# Adaptive Histogram Equalization (CLAHE)\n",
        "def clahe_equalization(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(gray)\n",
        "\n",
        "# Sobel Edge Detection\n",
        "def sobel_edge_detection(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    return cv2.magnitude(sobel_x, sobel_y)\n",
        "\n",
        "# Image Super-Resolution (Simple Example with Upscaling)\n",
        "def super_resolution(image):\n",
        "    return cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# Feature Extraction (ORB)\n",
        "def extract_orb_features(image):\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "    return cv2.drawKeypoints(image, keypoints, None, color=(0,255,0))\n",
        "\n",
        "# Contrast Enhancement (Adaptive Histogram Equalization - CLAHE)\n",
        "def enhance_contrast(image):\n",
        "    return clahe_equalization(image)\n",
        "\n",
        "# Convert images to uint8 format for proper display\n",
        "def convert_to_uint8(image):\n",
        "    if image.dtype != np.uint8:\n",
        "        image = np.uint8(np.clip(image, 0, 255))\n",
        "    return image\n",
        "\n",
        "# Apply all the preprocessing techniques to each image\n",
        "def process_image(image):\n",
        "    return {\n",
        "        \"Original\": image,\n",
        "        \"Bilateral Filter\": convert_to_uint8(bilateral_filter(image)),\n",
        "        \"CLAHE Equalization\": convert_to_uint8(clahe_equalization(image)),\n",
        "        \"Sobel Edge Detection\": convert_to_uint8(sobel_edge_detection(image)),\n",
        "        \"Super Resolution\": convert_to_uint8(super_resolution(image)),\n",
        "        \"ORB Feature Extraction\": convert_to_uint8(extract_orb_features(image)),\n",
        "        \"Contrast Enhancement\": convert_to_uint8(enhance_contrast(image))\n",
        "    }\n",
        "\n",
        "# Process each of the uploaded images\n",
        "agriculture_results = process_image(agriculture)\n",
        "manufacturing_results = process_image(manufacturing)\n",
        "road_results = process_image(road)\n",
        "medical_results = process_image(medical)\n",
        "satellite_results = process_image(satellite)\n",
        "\n",
        "# Example function to display all images\n",
        "def display_images(results):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for idx, (title, img) in enumerate(results.items()):\n",
        "        plt.subplot(2, 4, idx + 1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display results for each image\n",
        "print(\"Displaying processed results for Agriculture Image:\")\n",
        "display_images(agriculture_results)\n",
        "\n",
        "print(\"Displaying processed results for Manufacturing Image:\")\n",
        "display_images(manufacturing_results)\n",
        "\n",
        "print(\"Displaying processed results for Road Image:\")\n",
        "display_images(road_results)\n",
        "\n",
        "print(\"Displaying processed results for Medical Image:\")\n",
        "display_images(medical_results)\n",
        "\n",
        "print(\"Displaying processed results for Satellite Image:\")\n",
        "display_images(satellite_results)\n"
      ],
      "metadata": {
        "id": "50g5DKNS9uAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Code\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utility function to display images\n",
        "def display_images(images, titles, cmap=None, figsize=(15, 10)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(image, cmap=cmap if len(image.shape) == 2 else None)\n",
        "        plt.title(titles[i])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Load images\n",
        "agriculture = cv2.imread(\"/content/drive/MyDrive/agriculture.jpg\")\n",
        "manufacturing = cv2.imread(\"/content/drive/MyDrive/manufacturing.jpg\")\n",
        "road = cv2.imread(\"/content/drive/MyDrive/road.jpg\")\n",
        "medical=cv2.imread(\"/content/drive/MyDrive/medical.jpg\")\n",
        "satellite=cv2.imread(\"/content/drive/MyDrive/satellite.jpg\")\n",
        "\n",
        "\n",
        "# Preprocessing Functions\n",
        "# Denoising - Gaussian Blur\n",
        "def denoise_image(image):\n",
        "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Contrast Enhancement - Histogram Equalization (grayscale example)\n",
        "def enhance_contrast(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.equalizeHist(gray)\n",
        "\n",
        "# Perspective Transformation\n",
        "def perspective_transform(image):\n",
        "    height, width = image.shape[:2]\n",
        "    src_points = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])\n",
        "    dst_points = np.float32([[50, 50], [width - 50, 50], [50, height - 50], [width - 50, height - 50]])\n",
        "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "    return cv2.warpPerspective(image, matrix, (width, height))\n",
        "\n",
        "# Edge Detection - Canny\n",
        "def detect_edges(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.Canny(gray, 50, 150)\n",
        "\n",
        "# Color Space Conversion - RGB to HSV and thresholding\n",
        "def color_space_conversion(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    return cv2.inRange(hsv, (36, 25, 25), (70, 255, 255))  # Green mask\n",
        "\n",
        "# Apply preprocessing on the images\n",
        "# Apply all preprocessing techniques to each image\n",
        "processed_images = {\n",
        "    \"agriculture\": {\n",
        "        \"Denoising\": denoise_image(agriculture),\n",
        "        \"Contrast Enhancement\": enhance_contrast(agriculture),\n",
        "        \"Perspective Transformation\": perspective_transform(agriculture),\n",
        "        \"Edge Detection\": detect_edges(agriculture),\n",
        "        \"Color Space Conversion\": color_space_conversion(agriculture),\n",
        "    },\n",
        "    \"manufacturing\": {\n",
        "        \"Denoising\": denoise_image(manufacturing),\n",
        "        \"Contrast Enhancement\": enhance_contrast(manufacturing),\n",
        "        \"Perspective Transformation\": perspective_transform(manufacturing),\n",
        "        \"Edge Detection\": detect_edges(manufacturing),\n",
        "        \"Color Space Conversion\": color_space_conversion(manufacturing),\n",
        "    },\n",
        "    \"road\": {\n",
        "        \"Denoising\": denoise_image(road),\n",
        "        \"Contrast Enhancement\": enhance_contrast(road),\n",
        "        \"Perspective Transformation\": perspective_transform(road),\n",
        "        \"Edge Detection\": detect_edges(road),\n",
        "        \"Color Space Conversion\": color_space_conversion(road),\n",
        "    },\n",
        "    \"medical\": {\n",
        "        \"Denoising\": denoise_image(medical),\n",
        "        \"Contrast Enhancement\": enhance_contrast(medical),\n",
        "        \"Perspective Transformation\": perspective_transform(medical),\n",
        "        \"Edge Detection\": detect_edges(medical),\n",
        "        \"Color Space Conversion\": color_space_conversion(medical),\n",
        "    },\n",
        "    \"satellite\": {\n",
        "        \"Denoising\": denoise_image(satellite),\n",
        "        \"Contrast Enhancement\": enhance_contrast(satellite),\n",
        "        \"Perspective Transformation\": perspective_transform(satellite),\n",
        "        \"Edge Detection\": detect_edges(satellite),\n",
        "        \"Color Space Conversion\": color_space_conversion(satellite),\n",
        "    },\n",
        "}\n",
        "\n",
        "# Display results for each preprocessing applied to each image\n",
        "for image_name, preprocessing_results in processed_images.items():\n",
        "    print(f\"Results for {image_name.capitalize()}:\")\n",
        "    for preprocessing_name, processed_image in preprocessing_results.items():\n",
        "        display_images(\n",
        "            [cv2.cvtColor(eval(image_name), cv2.COLOR_BGR2RGB), processed_image],\n",
        "            [\"Original\", preprocessing_name],\n",
        "            cmap=\"gray\" if len(processed_image.shape) == 2 else None,\n",
        "        )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6xAbkRVu4zWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.exposure import match_histograms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load images\n",
        "agriculture = cv2.imread(\"/content/drive/MyDrive/agriculture.jpg\")\n",
        "manufacturing = cv2.imread(\"/content/drive/MyDrive/manufacturing.jpg\")\n",
        "road = cv2.imread(\"/content/drive/MyDrive/road.jpg\")\n",
        "medical = cv2.imread(\"/content/drive/MyDrive/medical.jpg\")\n",
        "satellite = cv2.imread(\"/content/drive/MyDrive/satellite.jpg\")\n",
        "\n",
        "# Preprocessing Functions\n",
        "\n",
        "# 1. Gamma Correction\n",
        "def gamma_correction(image, gamma=1.2):\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)\n",
        "\n",
        "# 2. Fourier Transform for Frequency Analysis\n",
        "def apply_fft(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    f = np.fft.fft2(gray)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
        "    return magnitude_spectrum\n",
        "\n",
        "# 3. Unsharp Masking\n",
        "def unsharp_mask(image, alpha=1.5, beta=-0.5):\n",
        "    blurred = cv2.GaussianBlur(image, (9, 9), 10.0)\n",
        "    sharpened = cv2.addWeighted(image, alpha, blurred, beta, 0)\n",
        "    return sharpened\n",
        "\n",
        "# 4. Hough Line Transform\n",
        "def hough_line_detection(image):\n",
        "    edges = cv2.Canny(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 50, 150)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "    result = image.copy()\n",
        "    if lines is not None:\n",
        "        for rho, theta in lines[:, 0]:\n",
        "            a, b = np.cos(theta), np.sin(theta)\n",
        "            x0, y0 = a * rho, b * rho\n",
        "            x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * a)\n",
        "            x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * a)\n",
        "            cv2.line(result, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    return result\n",
        "\n",
        "# 5. Morphological Transformations\n",
        "def morphological_operations(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "    return opening\n",
        "\n",
        "# 6. Histogram Matching\n",
        "def histogram_matching(image, reference):\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched\n",
        "\n",
        "# 7. Non-Local Means Denoising\n",
        "def non_local_means(image):\n",
        "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "\n",
        "# 8. Watershed Segmentation\n",
        "def watershed_segmentation(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg.astype(np.uint8))\n",
        "    markers = cv2.connectedComponents(sure_fg.astype(np.uint8))[1]\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "    result = cv2.watershed(image, markers)\n",
        "    return result\n",
        "\n",
        "# 9. Dense Optical Flow (Requires two images)\n",
        "def optical_flow(image1, image2):\n",
        "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    return flow\n",
        "\n",
        "# 10. Adaptive Thresholding\n",
        "def adaptive_threshold(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                 cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# Apply all preprocessing techniques to each image\n",
        "images = {\"agriculture\": agriculture, \"manufacturing\": manufacturing, \"road\": road,\n",
        "          \"medical\": medical, \"satellite\": satellite}\n",
        "\n",
        "results = {}\n",
        "for name, image in images.items():\n",
        "    results[name] = {\n",
        "        \"Gamma Correction\": gamma_correction(image),\n",
        "        \"FFT\": apply_fft(image),\n",
        "        \"Unsharp Mask\": unsharp_mask(image),\n",
        "        \"Hough Lines\": hough_line_detection(image),\n",
        "        \"Morphological Ops\": morphological_operations(image),\n",
        "        \"Non-Local Means\": non_local_means(image),\n",
        "        \"Adaptive Threshold\": adaptive_threshold(image)\n",
        "    }\n",
        "\n",
        "# Visualization Function\n",
        "def display_results(results):\n",
        "    for image_name, preprocess_results in results.items():\n",
        "        print(f\"Results for {image_name.capitalize()}:\")\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        for i, (method, result) in enumerate(preprocess_results.items()):\n",
        "            plt.subplot(3, 3, i + 1)\n",
        "            if len(result.shape) == 2:  # Grayscale image\n",
        "                plt.imshow(result, cmap=\"gray\")\n",
        "            else:\n",
        "                plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(method)\n",
        "            plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Display results\n",
        "display_results(results)\n"
      ],
      "metadata": {
        "id": "nD5UnCyUIT0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List of filenames (without paths) to delete\n",
        "files_to_delete = [\"medical.jpg\", \"manufacturing.jpg\", \"road.jpg\", \"satellite.jpg\", \"agriculture.jpg\"]\n",
        "\n",
        "# Path where Colab stores uploaded files\n",
        "base_path = \"/content/\"\n",
        "\n",
        "# Delete each file in the list if it exists\n",
        "for filename in files_to_delete:\n",
        "    file_path = os.path.join(base_path, filename)\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"Deleted: {filename}\")\n",
        "    else:\n",
        "        print(f\"File not found: {filename}\")\n",
        "\n",
        "# Confirm files are deleted\n",
        "print(\"Cleanup completed!\")\n"
      ],
      "metadata": {
        "id": "Vyc-leBieBje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}